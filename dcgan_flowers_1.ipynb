{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oSzDBnupFBJg"
   },
   "source": [
    "#Deep Convolutional Generative Adaptative Network DC-GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2FoRCnXFNk0"
   },
   "source": [
    "Some information about the project here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jFDtb-HBFSHD"
   },
   "source": [
    "#Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aLDb5yKuZmS"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "NUM_NEW_IMAGES = 1000\n",
    "DATASET_FOLDER = 'only_flowers/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CbtunS4kFlHo"
   },
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "U0HxU1J2MSNy",
    "outputId": "8b3edbe2-319a-40d0-da38-b63920785179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.18.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (7.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpQpeL4ZFvt3"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from glob import glob\n",
    "from IPython import display\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import pytz\n",
    "tz_NY = pytz.timezone('America/New_York') \n",
    "import random\n",
    "from scipy import ndarray\n",
    "import skimage as sk\n",
    "from skimage import io\n",
    "from skimage import util\n",
    "from skimage import transform\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D9EcQFsUKzeM"
   },
   "source": [
    "#Image presentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGfK0sPio0Bq"
   },
   "outputs": [],
   "source": [
    "def show_samples(sample_images):\n",
    "    \n",
    "    print(\"len(sample_images): \", len(sample_images))\n",
    "    print(\"len(sample_images): \", sample_images[0].shape)\n",
    "    \n",
    "    figure, axes = plt.subplots(1, len(sample_images), figsize = (50, 50))\n",
    "\n",
    "    print(\"figure: \", figure)\n",
    "    print(\"axes: \", axes)\n",
    "\n",
    "    for index, axis in enumerate(axes):\n",
    "        axis.axis('off')\n",
    "        image_array = sample_images[index]\n",
    "        axis.imshow(image_array)\n",
    "        \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uT0kRsVZyG52"
   },
   "outputs": [],
   "source": [
    "def show_image_custom(input_image):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    plt.imshow(input_image)\n",
    "\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NUX6W7M0n0Wg"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "##Fetch the  Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "colab_type": "code",
    "id": "4F5LndjimPia",
    "outputId": "9c0a9913-b25c-4767-ca52-0280771ddacf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fechting the Image Data Set\n",
      "--2020-04-06 19:29:32--  https://github.com/ravasconcelos/flowers_dcgan/raw/master/only_flowers.zip\n",
      "Resolving github.com (github.com)... 140.82.113.4\n",
      "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/ravasconcelos/flowers_dcgan/master/only_flowers.zip [following]\n",
      "--2020-04-06 19:29:33--  https://raw.githubusercontent.com/ravasconcelos/flowers_dcgan/master/only_flowers.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10177417 (9.7M) [application/zip]\n",
      "Saving to: ‘only_flowers.zip.2’\n",
      "\n",
      "only_flowers.zip.2  100%[===================>]   9.71M  5.59MB/s    in 1.7s    \n",
      "\n",
      "2020-04-06 19:29:37 (5.59 MB/s) - ‘only_flowers.zip.2’ saved [10177417/10177417]\n",
      "\n",
      "Unzipping the file\n",
      "Flower images are available\n",
      "Number of images:  1251\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a277f992e713>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnum_of_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of images: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnum_of_images\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m249\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "GET_DATASET = True\n",
    "if GET_DATASET:\n",
    "    print('Fechting the Image Data Set')\n",
    "    !wget https://github.com/ravasconcelos/flowers_dcgan/raw/master/only_flowers.zip\n",
    "    print('Unzipping the file')\n",
    "    ZIP_FILE = '/content/only_flowers.zip'\n",
    "    !unzip -q -o $ZIP_FILE\n",
    "    print('Flower images are available')\n",
    "#Check if there are some files in the folder\n",
    "num_of_images = len(os.listdir(DATASET_FOLDER))\n",
    "print('Number of images: ', num_of_images) \n",
    "assert num_of_images == 249 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40CxidI1IBpm"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qYP62OBlIL9q"
   },
   "source": [
    "Image transformation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OjJtLwKqwsUU"
   },
   "outputs": [],
   "source": [
    "def random_rotation(image_array: ndarray):\n",
    "    # pick a random degree of rotation between 20% on the left and 20% on the right\n",
    "    random_degree = random.uniform(-20, 20)\n",
    "    return sk.transform.rotate(image_array, random_degree)\n",
    "\n",
    "def horizontal_flip(image_array: ndarray):\n",
    "    # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n",
    "    return image_array[:, ::-1]\n",
    "\n",
    "def vertical_flip(image_array: ndarray):\n",
    "    return image_array[::-1, :]\n",
    "\n",
    "def vertical_and_horizontal_flip(image_array: ndarray):\n",
    "    h_flip_image = vertical_flip(image_array)\n",
    "    return horizontal_flip(h_flip_image)\n",
    "\n",
    "def rescale(image_array: ndarray):\n",
    "    rescaled_image = sk.transform.rescale(image_array, 0.5, anti_aliasing=False)\n",
    "    return sk.transform.resize(rescaled_image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "def TF_crop_pad(x, n_pixels=20, pad_mode='edge'):\n",
    "    \"\"\"Pad image by n_pixels on each size, then take random crop of same\n",
    "    original size.\n",
    "    \"\"\"\n",
    "    assert len(x.shape) == 3\n",
    "    h, w, nc = x.shape\n",
    "\n",
    "    # First pad image by n_pixels on each side\n",
    "    padded = sk.util.pad(x, [(n_pixels, n_pixels) for _ in range(2)] + [(0,0)],\n",
    "        mode=pad_mode)\n",
    "\n",
    "    # Then take a random crop of the original size\n",
    "    crops = [(c, 2*n_pixels-c) for c in np.random.randint(0, 2*n_pixels+1, [2])]\n",
    "    # For channel dimension don't do any cropping\n",
    "    crops += [(0,0)]\n",
    "    return sk.transform.resize(sk.util.crop(padded, crops, copy=True), (IMAGE_SIZE, IMAGE_SIZE))     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PNnixXQxIVQE"
   },
   "source": [
    "Create the new images doing random transformation on random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbdAWEZKwsRn"
   },
   "outputs": [],
   "source": [
    "# dictionary of the transformations we defined earlier\n",
    "available_transformations = {\n",
    "    'rotate': random_rotation,\n",
    "    'vertical_flip': vertical_flip,\n",
    "    'horizontal_flip': horizontal_flip,\n",
    "    'vertical_and_horizontal_flip': vertical_and_horizontal_flip,\n",
    "    'TF_crop_pad': TF_crop_pad\n",
    "}\n",
    "\n",
    "folder_path = DATASET_FOLDER\n",
    "\n",
    "# find all files paths from the folder\n",
    "images = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "num_generated_files = 0\n",
    "while num_generated_files <= NUM_NEW_IMAGES:\n",
    "    # random image from the folder\n",
    "    image_path = random.choice(images)\n",
    "    # read image as an two dimensional array of pixels\n",
    "    image_to_transform = sk.io.imread(image_path)\n",
    "    # random num of transformation to apply\n",
    "    num_transformations_to_apply = random.randint(1, len(available_transformations))\n",
    "\n",
    "    num_transformations = 0\n",
    "    transformed_image = None\n",
    "    while num_transformations <= num_transformations_to_apply:\n",
    "        # random transformation to apply for a single image\n",
    "        key = random.choice(list(available_transformations))\n",
    "        transformed_image = available_transformations[key](image_to_transform)\n",
    "        num_transformations += 1\n",
    "\n",
    "        new_file_path = '%s/augmented_image_%s.jpg' % (folder_path, num_generated_files)\n",
    "\n",
    "        # write image to the disk\n",
    "        #io.imsave(new_file_path, transformed_image.astype(np.uint8))\n",
    "        io.imsave(new_file_path, transformed_image)\n",
    "        num_generated_files += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukxWQA_CmQhP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "### Load and prepare the dataset\n",
    "\n",
    "You will use the MNIST dataset to train the generator and the discriminator. The generator will generate handwritten digits resembling the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nWJfwVmmQjL"
   },
   "outputs": [],
   "source": [
    "input_images = np.asarray([np.asarray(\n",
    "    Image.open(file)\n",
    "    .resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "    ) for file in glob(DATASET_FOLDER+'*')])\n",
    "print (\"Input: \" + str(input_images.shape))\n",
    "\n",
    "np.random.shuffle(input_images)\n",
    "\n",
    "sample_images = input_images[:5]\n",
    "show_samples(sample_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYUjcQhGsXmo"
   },
   "outputs": [],
   "source": [
    "input_images.shape\n",
    "len(input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hgYH0lzSt6jj"
   },
   "outputs": [],
   "source": [
    "show_image_custom(input_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "81_8Pm3Wt65I"
   },
   "outputs": [],
   "source": [
    "show_image_custom(vertical_flip(input_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hz7-J9Vpt7R4"
   },
   "outputs": [],
   "source": [
    "show_image_custom(horizontal_flip(input_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "57cJF8kiuZXV"
   },
   "outputs": [],
   "source": [
    "show_image_custom(random_rotation(input_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NdISbuOauchY"
   },
   "outputs": [],
   "source": [
    "show_image_custom(vertical_and_horizontal_flip(input_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0H5pjlrrkZS"
   },
   "outputs": [],
   "source": [
    "train_images = input_images.reshape(input_images.shape[0], 256, 256, 3).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rKUBgK9riO6"
   },
   "outputs": [],
   "source": [
    "train_images2 = (train_images * 127.5) + 127.5\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "plt.imshow(train_images2[0].astype(np.uint8) )\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OprTtWULwiiQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4PIDhoDLbsZ"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = input_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yKCCQOoJ7cn"
   },
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "## Create the models\n",
    "\n",
    "Both the generator and discriminator are defined using the [Keras Sequential API](https://www.tensorflow.org/guide/keras#sequential_model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tEyxE-GMC48"
   },
   "source": [
    "### The Generator\n",
    "\n",
    "The generator uses `tf.keras.layers.Conv2DTranspose` (upsampling) layers to produce an image from a seed (random noise). Start with a `Dense` layer that takes this seed as input, then upsample several times until you reach the desired image size of 256x256x3. Notice the `tf.keras.layers.LeakyReLU` activation for each layer, except the output layer which uses tanh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bpTcDqoLWjY"
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(8*8*512, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((8, 8, 512)))\n",
    "    assert model.output_shape == (None, 8, 8, 512) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 8, 8, 256)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 16, 16, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 32, 32, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 64, 64, 32)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(16, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 128, 128, 16)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 256, 256, 3)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GyWgG09LCSJl"
   },
   "source": [
    "Use the (as yet untrained) generator to create an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gl7jcC7TdPTG"
   },
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "generated_image2 = generated_image[0].numpy() * 127.5 + 127.5\n",
    "\n",
    "plt.imshow(generated_image2.astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0IKnaCtg6WE"
   },
   "source": [
    "### The Discriminator\n",
    "\n",
    "The discriminator is a CNN-based image classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dw2tPLmk2pEP"
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(16, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[256, 256, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhPneagzCaQv"
   },
   "source": [
    "Use the (as yet untrained) discriminator to classify the generated images as real or fake. The model will be trained to output positive values for real images, and negative values for fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDkA05NE6QMs"
   },
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## Define the loss and optimizers\n",
    "\n",
    "Define loss functions and optimizers for both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psQfmXxYKU3X"
   },
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKY_iPSPNWoj"
   },
   "source": [
    "### Discriminator loss\n",
    "\n",
    "This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jd-3GCUEiKtv"
   },
   "source": [
    "### Generator loss\n",
    "The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1). Here, we will compare the discriminators decisions on the generated images to an array of 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MgIc7i0th_Iu"
   },
   "source": [
    "The discriminator and the generator optimizers are different since we will train two networks separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWtinsGDPJlV"
   },
   "source": [
    "### Save checkpoints\n",
    "This notebook also demonstrates how to save and restore models, which can be helpful in case a long running training task is interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CA1w-7s2POEy"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## Define the training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzrfHPuOOaUl"
   },
   "outputs": [],
   "source": [
    "def summarize_epoch(epoch, d_losses, g_losses, save_image=True):\n",
    "  \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(d_losses, label='Discriminator', alpha=0.6)\n",
    "    plt.plot(g_losses, label='Generator', alpha=0.6)\n",
    "    plt.title(\"Losses\")\n",
    "    plt.legend()\n",
    "    if save_image:\n",
    "        plt.savefig(\"losses_\" + str(epoch) + \".png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jylSonrqSWfi"
   },
   "source": [
    "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3t5ibNo05jCB"
   },
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  print('Training started at: ', datetime.now(tz_NY))\n",
    "  save_image = False\n",
    "  d_losses = []\n",
    "  g_losses = []\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      d_loss, g_loss = train_step(image_batch)\n",
    "      d_losses.append(d_loss)\n",
    "      g_losses.append(g_loss)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "      save_image = True\n",
    "\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed,\n",
    "                             save_image)\n",
    "    summarize_epoch(epoch, d_losses, g_losses, save_image)\n",
    "    save_image = False\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)\n",
    "  summarize_epoch(epoch, d_losses, g_losses)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aFF7Hk3XdeW"
   },
   "source": [
    "**Generate and save images**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input, save_image=True):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      generated_image2 = predictions[i].numpy() * 127.5 + 127.5\n",
    "      plt.imshow(generated_image2.astype('uint8'))\n",
    "\n",
    "      plt.axis('off')\n",
    "\n",
    "  if save_image:\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YgwgHAwKbA7g"
   },
   "outputs": [],
   "source": [
    "def show_samples2(sample_images):\n",
    "    figure, axes = plt.subplots(1, len(sample_images), figsize = (50, 50))\n",
    "\n",
    "    for index, axis in enumerate(axes):\n",
    "        axis.axis('off')\n",
    "        image_array = sample_images[index]\n",
    "        image_array = image_array.numpy() * 127.5 + 127.5\n",
    "        axis.imshow(image_array.astype(np.uint8))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZrd4CdjR-Fp"
   },
   "source": [
    "## Train the model\n",
    "Call the `train()` method defined above to train the generator and discriminator simultaneously. Note, training GANs can be tricky. It's important that the generator and discriminator do not overpower each other (e.g., that they train at a similar rate).\n",
    "\n",
    "At the beginning of the training, the generated images look like random noise. As training progresses, the generated digits will look increasingly real. After about 50 epochs, they resemble MNIST digits. This may take about one minute / epoch with the default settings on Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OG-WSs7B5N35"
   },
   "outputs": [],
   "source": [
    "casdasd sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ly3UN0SLLY2l"
   },
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhJAoyv9aq4-"
   },
   "outputs": [],
   "source": [
    "checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rUuUUJf09uEb"
   },
   "outputs": [],
   "source": [
    "train(train_dataset, 1)\n",
    "\n",
    "noise = tf.random.normal([5, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "show_samples2(generated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJo1bXQ803WW"
   },
   "outputs": [],
   "source": [
    "noise = tf.random.normal([5, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "show_samples2(generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2F_nmw0FyeAW"
   },
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "generated_image2 = generated_image[0].numpy() * 127.5 + 127.5\n",
    "\n",
    "plt.imshow(generated_image2.astype(np.uint8))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGbSuTizj8fI"
   },
   "outputs": [],
   "source": [
    "CHKP_INDEX = '923'\n",
    "def download_checkpoint():\n",
    "    try:\n",
    "        from google.colab import files\n",
    "    except ImportError:\n",
    "        pass\n",
    "    else:\n",
    "        files.download('training_checkpoints/ckpt-'+CHKP_INDEX+'.data-00000-of-00002')\n",
    "        #files.download('training_checkpoints/ckpt-'+CHKP_INDEX+'.data-00001-of-00002')\n",
    "        files.download('training_checkpoints/ckpt-'+CHKP_INDEX+'.index')\n",
    "        files.download('training_checkpoints/checkpoint')\n",
    "\n",
    "if CHKP_INDEX != '':\n",
    "    download_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfM4YcPVPkNO"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "To restore a checkpoint upload a the ckpt files into training_checkpoints folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sRWu1NCR_wgi"
   },
   "outputs": [],
   "source": [
    "!ls -la training_checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XhXsd0srPo8c"
   },
   "outputs": [],
   "source": [
    "# upload the files (checkpoint, ckpt-xxx.index, ckpt-xxx.data-*) into training_checkpoints folder\n",
    "RESTORE_CHECKPOINT = True\n",
    "if RESTORE_CHECKPOINT:\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4M_vIbUi7c0"
   },
   "source": [
    "## Create a GIF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WfO5wCdclHGL"
   },
   "outputs": [],
   "source": [
    "# Display a single image using the epoch number\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5x3q9_Oe5q0A"
   },
   "outputs": [],
   "source": [
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NywiH3nL8guF"
   },
   "source": [
    "Use `imageio` to create an animated gif using the images saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IGKQgENQ8lEI"
   },
   "outputs": [],
   "source": [
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  last = -1\n",
    "  for i,filename in enumerate(filenames):\n",
    "    frame = 2*(i**0.5)\n",
    "    if round(frame) > round(last):\n",
    "      last = frame\n",
    "    else:\n",
    "      continue\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)\n",
    "\n",
    "import IPython\n",
    "if IPython.version_info > (6,2,0,''):\n",
    "  display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGhC3-fMWSwl"
   },
   "source": [
    "If you're working in Colab you can download the animation with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uV0yiKpzNP1b"
   },
   "outputs": [],
   "source": [
    "DOWNLOAD = False\n",
    "if DOWNLOAD:\n",
    "    try:\n",
    "        from google.colab import files\n",
    "    except ImportError:\n",
    "        pass\n",
    "    else:\n",
    "        files.download(anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K2FANCpij4zE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k6qC-SbjK0yW"
   },
   "source": [
    "# More information about GAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjjkT9KAK6H7"
   },
   "source": [
    "To learn more about GANs we recommend the [NIPS 2016 Tutorial: Generative Adversarial Networks](https://arxiv.org/abs/1701.00160).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wunG8sGLTbs8"
   },
   "source": [
    "#Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60Y9XB5fcXrT"
   },
   "outputs": [],
   "source": [
    "!rm losses_*\n",
    "!rm image_*\n",
    "!rm only_flowers/au*\n",
    "#!rm -r only_flowers/\n",
    "#!rm only_flowers.zip*\n",
    "#!rm -r __MACOSX/\n",
    "#!rm dcgan.gif\n",
    "#!rm -r training_checkpoints/\n",
    "#!ls -la training_checkpoints/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "P9E_pO4w8CGi",
    "outputId": "cfbb2092-c519-4e34-f884-c60564f5bcb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\n"
     ]
    }
   ],
   "source": [
    "!echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHAHKHkk9NQY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "xmhXjwrg8jVF",
    "outputId": "2f84df41-5c69-4f11-c1fe-4b3526a6ddb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "ca-certificates is already the newest version (20180409).\n",
      "gnupg is already the newest version (2.2.4-1ubuntu1.2).\n",
      "gnupg set to manually installed.\n",
      "The following NEW packages will be installed:\n",
      "  apt-transport-https\n",
      "0 upgraded, 1 newly installed, 0 to remove and 25 not upgraded.\n",
      "Need to get 1,692 B of archives.\n",
      "After this operation, 153 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 apt-transport-https all 1.6.12 [1,692 B]\n",
      "Fetched 1,692 B in 0s (5,948 B/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package apt-transport-https.\n",
      "(Reading database ... 144568 files and directories currently installed.)\n",
      "Preparing to unpack .../apt-transport-https_1.6.12_all.deb ...\n",
      "Unpacking apt-transport-https (1.6.12) ...\n",
      "Setting up apt-transport-https (1.6.12) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install apt-transport-https ca-certificates gnupg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "WT7zrFys9OTG",
    "outputId": "3dda800e-0f21-4418-d16b-a4e37d833c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   653  100   653    0     0   8706      0 --:--:-- --:--:-- --:--:--  8706\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1eQB4CjL9t-b",
    "outputId": "a0ba3d5c-f873-4d28-b8e9-7de86e1d4bd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [Working]\r",
      "            \r",
      "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "\r",
      "0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Waiting for headers] [Wa\r",
      "                                                                               \r",
      "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
      "\r",
      "0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Waiting for headers] [2 \r",
      "0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Waiting for headers] [Wa\r",
      "0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r",
      "                                                                               \r",
      "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "\r",
      "0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r",
      "                                                                               \r",
      "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "\r",
      "0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r",
      "                                                                               \r",
      "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "\r",
      "0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [5 InRelease 2,589 B/88.7 k\r",
      "                                                                               \r",
      "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "\r",
      "0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [5 InRelease 2,589 B/88.7 k\r",
      "                                                                               \r",
      "Get:7 https://packages.cloud.google.com/apt cloud-sdk InRelease [6,340 B]\n",
      "\r",
      "0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [5 InRelease 14.2 kB/88.7 k\r",
      "0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [5 InRelease 14.2 kB/88.7 k\r",
      "0% [Waiting for headers] [5 InRelease 14.2 kB/88.7 kB 16%] [Waiting for headers\r",
      "0% [Release.gpg gpgv 564 B] [Waiting for headers] [5 InRelease 14.2 kB/88.7 kB \r",
      "                                                                               \r",
      "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:13 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [101 kB]\n",
      "Get:14 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
      "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [835 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:17 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,810 kB]\n",
      "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [38.5 kB]\n",
      "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [873 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,368 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [57.5 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,176 kB]\n",
      "Get:23 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [873 kB]\n",
      "Fetched 7,408 kB in 3s (2,248 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  python-crcmod\n",
      "Suggested packages:\n",
      "  google-cloud-sdk-app-engine-java google-cloud-sdk-app-engine-python\n",
      "  google-cloud-sdk-pubsub-emulator google-cloud-sdk-bigtable-emulator\n",
      "  google-cloud-sdk-datastore-emulator kubectl\n",
      "The following NEW packages will be installed:\n",
      "  google-cloud-sdk python-crcmod\n",
      "0 upgraded, 2 newly installed, 0 to remove and 31 not upgraded.\n",
      "Need to get 46.6 MB of archives.\n",
      "After this operation, 274 MB of additional disk space will be used.\n",
      "Get:1 https://packages.cloud.google.com/apt cloud-sdk/main amd64 google-cloud-sdk all 287.0.0-0 [46.6 MB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-crcmod amd64 1.7-2build4 [17.5 kB]\n",
      "Fetched 46.6 MB in 1s (75.0 MB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package python-crcmod.\n",
      "(Reading database ... 144572 files and directories currently installed.)\n",
      "Preparing to unpack .../python-crcmod_1.7-2build4_amd64.deb ...\n",
      "Unpacking python-crcmod (1.7-2build4) ...\n",
      "Selecting previously unselected package google-cloud-sdk.\n",
      "Preparing to unpack .../google-cloud-sdk_287.0.0-0_all.deb ...\n",
      "Unpacking google-cloud-sdk (287.0.0-0) ...\n",
      "Setting up python-crcmod (1.7-2build4) ...\n",
      "Setting up google-cloud-sdk (287.0.0-0) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update && sudo apt-get install google-cloud-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iKAiHekP-Ozg",
    "outputId": "54e001fe-9422-46ae-cc65-af8614247f9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! This command will take you through the configuration of gcloud.\n",
      "\n",
      "Settings from your current configuration [default] are:\n",
      "component_manager:\n",
      "  disable_update_check: 'true'\n",
      "compute:\n",
      "  gce_metadata_read_timeout_sec: '0'\n",
      "core:\n",
      "  disable_usage_reporting: 'True'\n",
      "\n",
      "Pick configuration to use:\n",
      " [1] Re-initialize this configuration [default] with new settings \n",
      " [2] Create a new configuration\n",
      "Please enter your numeric choice:  \n",
      "Please enter a value between 1 and 2:  1\n",
      "\n",
      "Your current configuration has been set to: [default]\n",
      "\n",
      "You can skip diagnostics next time by using the following flag:\n",
      "  gcloud init --skip-diagnostics\n",
      "\n",
      "Network diagnostic detects and fixes local network connection issues.\n",
      "Reachability Check passed.\n",
      "Network diagnostic passed (1/1 checks passed).\n",
      "\n",
      "You must log in to continue. Would you like to log in (Y/n)?  Y\n",
      "\n",
      "Go to the following link in your browser:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?code_challenge=-t890WGgnNIrxevxYdXpSpWyZO6Ol-BMLe2w3KqtjZ8&prompt=select_account&code_challenge_method=S256&access_type=offline&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth\n",
      "\n",
      "\n",
      "Enter verification code: 4/yQH5kJUKOgAyIJ31iIHpPTKET_5hApZ5B2rHQVrbsD0zTRALK2-tXKs\n",
      "You are logged in as: [ravasconcelos@gmail.com].\n",
      "\n",
      "Pick cloud project to use: \n",
      " [1] pro-flux-273300\n",
      " [2] subtle-anthem-273323\n",
      " [3] Create a new project\n",
      "Please enter numeric choice or text value (must exactly match list \n",
      "item):  1\n",
      "\n",
      "Your current project has been set to: [pro-flux-273300].\n",
      "\n",
      "Do you want to configure a default Compute Region and Zone? (Y/n)?  Y\n",
      "\n",
      "Which Google Compute Engine zone would you like to use as project \n",
      "default?\n",
      "If you do not specify a zone via a command line flag while working \n",
      "with Compute Engine resources, the default is assumed.\n",
      " [1] us-east1-b\n",
      " [2] us-east1-c\n",
      " [3] us-east1-d\n",
      " [4] us-east4-c\n",
      " [5] us-east4-b\n",
      " [6] us-east4-a\n",
      " [7] us-central1-c\n",
      " [8] us-central1-a\n",
      " [9] us-central1-f\n",
      " [10] us-central1-b\n",
      " [11] us-west1-b\n",
      " [12] us-west1-c\n",
      " [13] us-west1-a\n",
      " [14] europe-west4-a\n",
      " [15] europe-west4-b\n",
      " [16] europe-west4-c\n",
      " [17] europe-west1-b\n",
      " [18] europe-west1-d\n",
      " [19] europe-west1-c\n",
      " [20] europe-west3-c\n",
      " [21] europe-west3-a\n",
      " [22] europe-west3-b\n",
      " [23] europe-west2-c\n",
      " [24] europe-west2-b\n",
      " [25] europe-west2-a\n",
      " [26] asia-east1-b\n",
      " [27] asia-east1-a\n",
      " [28] asia-east1-c\n",
      " [29] asia-southeast1-b\n",
      " [30] asia-southeast1-a\n",
      " [31] asia-southeast1-c\n",
      " [32] asia-northeast1-b\n",
      " [33] asia-northeast1-c\n",
      " [34] asia-northeast1-a\n",
      " [35] asia-south1-c\n",
      " [36] asia-south1-b\n",
      " [37] asia-south1-a\n",
      " [38] australia-southeast1-b\n",
      " [39] australia-southeast1-c\n",
      " [40] australia-southeast1-a\n",
      " [41] southamerica-east1-b\n",
      " [42] southamerica-east1-c\n",
      " [43] southamerica-east1-a\n",
      " [44] asia-east2-a\n",
      " [45] asia-east2-b\n",
      " [46] asia-east2-c\n",
      " [47] asia-northeast2-a\n",
      " [48] asia-northeast2-b\n",
      " [49] asia-northeast2-c\n",
      " [50] asia-northeast3-a\n",
      "Did not print [18] options.\n",
      "Too many options [68]. Enter \"list\" at prompt to print choices fully.\n",
      "Please enter numeric choice or text value (must exactly match list \n",
      "item):  8\n",
      "\n",
      "Your project default Compute Engine zone has been set to [us-central1-a].\n",
      "You can change it by running [gcloud config set compute/zone NAME].\n",
      "\n",
      "Your project default Compute Engine region has been set to [us-central1].\n",
      "You can change it by running [gcloud config set compute/region NAME].\n",
      "\n",
      "Created a default .boto configuration file at [/root/.boto]. See this file and\n",
      "[https://cloud.google.com/storage/docs/gsutil/commands/config] for more\n",
      "information about configuring Google Cloud Storage.\n",
      "Your Google Cloud SDK is configured and ready to use!\n",
      "\n",
      "* Commands that require authentication will use ravasconcelos@gmail.com by default\n",
      "* Commands will reference project `pro-flux-273300` by default\n",
      "* Compute Engine commands will use region `us-central1` by default\n",
      "* Compute Engine commands will use zone `us-central1-a` by default\n",
      "\n",
      "Run `gcloud help config` to learn how to change individual settings\n",
      "\n",
      "This gcloud configuration is called [default]. You can create additional configurations if you work with multiple accounts and/or projects.\n",
      "Run `gcloud topic configurations` to learn more.\n",
      "\n",
      "Some things to try next:\n",
      "\n",
      "* Run `gcloud --help` to see the Cloud Platform services you can interact with. And run `gcloud help COMMAND` to get help on any gcloud command.\n",
      "* Run `gcloud topic --help` to learn about advanced features of the SDK like arg files and output formatting\n"
     ]
    }
   ],
   "source": [
    "!gcloud init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "VPCo07NM-vxO",
    "outputId": "d5cc583e-d9d8-42a6-dfb6-479c0a2dbf05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://rodolfo-bucket-1/download.png...\n",
      "/ [1 files][  1.8 MiB/  1.8 MiB]                                                \n",
      "Operation completed over 1 objects/1.8 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://rodolfo-bucket-1/*.png ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "bJvq5mLE_JIm",
    "outputId": "f05db00f-8fff-4711-c0e2-7074ac5e5ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1912\n",
      "drwxr-xr-x 1 root root    4096 Apr  7 00:13 .\n",
      "drwxr-xr-x 1 root root    4096 Apr  6 23:45 ..\n",
      "drwxr-xr-x 1 root root    4096 Apr  7 00:10 .config\n",
      "-rw-r--r-- 1 root root 1930933 Apr  7 00:13 download.png\n",
      "drwxr-xr-x 1 root root    4096 Apr  3 16:24 sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls -la\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "M3dHNHEq_Ooj",
    "outputId": "9acb49db-be6e-45de-f696-acae2382f2d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://sample_data/anscombe.json [Content-Type=application/json]...\n",
      "Copying file://sample_data/california_housing_test.csv [Content-Type=text/csv]...\n",
      "Copying file://sample_data/california_housing_train.csv [Content-Type=text/csv]...\n",
      "Copying file://sample_data/mnist_test.csv [Content-Type=text/csv]...\n",
      "\\ [4 files][ 19.4 MiB/ 19.4 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://sample_data/mnist_train_small.csv [Content-Type=text/csv]...\n",
      "Copying file://sample_data/README.md [Content-Type=text/markdown]...\n",
      "/ [6 files][ 54.2 MiB/ 54.2 MiB]                                                \n",
      "Operation completed over 6 objects/54.2 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r sample_data/* gs://rodolfo-bucket-1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan_flowers.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
